# MIT 6.824 分布式系统

线程：有一个属于自己的程序计数器、一套寄存器和一个栈

多线程原因：1. I/O并发  2.并行化 3.易用性

​		      

## `MapReduce`

`Map`函数：一个key和一个value作为参数，key是输入文件的名字，value是输入文件的内容

输出写入中间文件，中间文件合理命名约定是 `mr-X-Y` ，其中X是Map任务编号，Y是Reduce任务编号。

`Reduce`函数：一个key和一个value作为参数，其中value是一个数组，里面每一个元素是Map函数输出的key的一个实例的value。

Worker 实现应该将第 X 个reduce 任务的输出放入文件中 `mr-out-X` 。

## `GFS`

### 设计目标

大型、快速、分割存储、自动修复、一个数据中心、内部使用

### Master节点

Master节点用来管理文件和Chunk的信息，而Chunk服务器用来存储实际的数据。

Master节点读数据只会从内存读，但是写数据的时候，至少有一部分数据会接入到磁盘中。更具体来说，Master会在磁盘上存储log，每次有数据变更时，Master会在磁盘的log中追加一条记录，并生成CheckPoint（类似于备份点）。

`NV`(non-volatile，非易失，写入磁盘)：

1. Chunk Handle的数组（第一个表单）
2. 版本号

`V`(volatile，不用写入磁盘)：

1. Chunk服务器列表
2. 主Chunk的ID
3. 租约过期时间

### `GFS`读文件

第一步是客户端（或者应用程序）将文件名和偏移量发送给Master。

第二步，Master节点将Chunk Handle（也就是ID，记为H）和服务器列表发送给客户端。

Chunk服务器需要做的就是根据文件名找到对应的Chunk文件，之后从文件中读取对应的数据段，并将数据返回给客户端。



## `VMware FT`

容错本身是为了提供高可用性。

处理故障的方法：复制。

两种复制的方法：

1. 状态转移 

   状态转移背后的思想是，Primary将自己完整状态，比如说内存中的内容，拷贝并发送给Backup。2.复制状态机

2. 复制状态机

   复制状态机不会在不同的副本之间发送状态，相应的，它只会从Primary将这些外部事件，例如外部的输入，发送给Backup



## `Raft1`

脑裂：在分布式系统中，由于网络或节点故障等原因，导致一个分布式系统被分为多个独立的子系统，每个子系统独立运行，无法相互通信，通时认为自己是整个系统的主节点，这就会导致整个系统失去一致性和可用性 

过半票决：如果系统有 2 * F + 1 个服务器，那么系统最多可以接受F个服务器出现故障，仍然可以正常工作。

一个基于Raft的多副本服务，每个服务的副本由两部分组成：应用程序代码和Raft库。应用程序代码接收`RPC`或者其他客户端请求；不同节点的Raft库之间相互合作，来维护多副本之间的操作同步。

从软件的角度来看一个Raft节点，节点上层是应用程序代码，下层是Raft层，应用层对Raft层进行函数调用，传递自己的状态和Raft反馈的信息，Raft层会帮助应用程序将其状态拷贝到其他副本节点。

### Log同步时序

![image-20241028131813528](/home/noregret/.config/Typora/typora-user-images/image-20241028131813528.png)

(1) 客户端向服务器1发送请求

(2) 服务器1的Raft层发送一个添加日志（`AppendEntries`）的`RPC`到其他两个副本。服务器1等待过半节点（包括Leader自己）的响应返回。

(3) 当Leader收到了过半服务器的正确响应，Leader会执行（来自客户端的）请求，得到结果，并将结果返回给客户端。

(4) 下一次Leader需要发送心跳，或者是收到了一个新的客户端请求，要将这个请求同步给其他副本时，Leader会将新的更大的commit号随着`AppendEntries`消息发出，当其他副本收到了这个消息，就知道之前的commit号已经被Leader提交，其他副本接下来也会执行相应的请求，更新本地的状态。

### Raft Log

Log对于Raft系统的重要性：

1. Log是Leader用来对操作排序的一种手段。对于这些复制状态机来说，所有副本不仅要执行相同的操作，还需要用相同的顺序执行这些操作。Log与其他很多事物，共同构成了Leader对接收到的客户端操作分配顺序的机制。

2. 对于Raft的Follower来说，Log是用来存放临时操作的地方。Follower直到收到Leader发送的新的commit号才执行这些操作。

3. 对于Leader节点来说，Log是用来存放客户端请求拷贝的地方。即使对那些已经commit的请求，为了能够向丢失了相应操作的副本重传，也需要存储在Leader的Log中。

4. Log可以帮助重启的服务器恢复状态。Log被用来持久化存储操作，服务器可以依赖这些操作来恢复状态。

### Leader选举

Raft中使用任期号来区分不同的Leader，每个任期最多只有一个Leader

**Leader创建方式**：每个Raft节点都有一个选举定时器，如果在定时器时间耗尽之前，当前节点没有收到任何当前Leader的消息，这个节点会认为Leader已经下线，并开始一次选举。

**开始一次选举**：当前服务器会增加任期号，并向所有的Raft节点发出请求投票`RPC`。其实只需要发送到N-1个节点，因为Raft规定了，Leader的候选人总是会在选举时投票给自己。

（1）如果Leader的确出现了故障，那么一定会有新的选举。

（2）如果Leader没有故障，我们仍然有可能会有一次新的选举。比如，如果网络很慢，丢了几个心跳，或者其他原因，这时，尽管Leader还在健康运行，我们可能会有某个选举定时器超时了，进而开启一次新的选举。



Raft是如何做到确保每个任期最多只有一个Leader的？

（1）为了能够当选，Raft要求一个候选人从过半服务器中获得认可投票。

（2）每个Raft节点，只会在一个任期内投出一个认可选票。

这意味着，在任意一个任期内，每一个节点只会对一个候选人投一次票。这样，就不可能有两个候选人同时获得过半的选票，因为每个节点只会投票一次。



如果一次选举成功了，整个集群的节点是如何知道的呢？

Raft规定，（1）赢得选举的服务器需要立刻发送一条`AppendEntries`消息给其他所有的服务器。

（2）除非是当前任期的Leader，没人可以发出`AppendEntries`消息。

所以假设我是一个服务器，我发现对于任期19有一次选举，过了一会我收到了一条`AppendEntries`消息，这个消息的任期号就是19。那么这条消息告诉我，我不知道的某个节点赢得了任期19的选举。所以，其他服务器通过接收特定任期号的`AppendEntries`来知道，选举成功了。

### 选举定时器

任何一条`AppendEntries`消息都会重置所有Raft节点的选举定时器。

分割选票：所有节点的定时器超时时间相同，他们都在同一时间到期，所有节点投票给自己，没有人获得过半选票，又会进行一次选举，这个状态可能会一直持续下去。

为了使这个场景出现的概率降低，Raft为选举定时器随机的选择超时时间。

![image-20241029231922283](/home/noregret/.config/Typora/typora-user-images/image-20241029231922283.png)

选举定时器的超时时间的设置：

1. 下限：Leader的心跳间隔。

​       心跳间隔（两个`AE`之间）    将选举定时器的超时时间（min）下限设置成心跳间隔的几倍

2. 上限：最大超时时间影响了系统能多快从故障中恢复。

   上限越大，系统的恢复时间也就越长。

3. 不同节点的选举定时器的超时时间差（`S2`和`S3`之间）必须要足够长，使得第一个开始选举的节点能够完成一轮选举。这里至少需要大于发送一条`RPC`所需要的往返（Round-Trip）时间。

4. 每一次一个节点重置自己的选举定时器时，都需要重新选择一个随机的超时时间。

### 日志恢复

<img src="/home/noregret/.config/Typora/typora-user-images/image-20241030185207703.png" alt="image-20241030185207703" style="zoom: 67%;" />

Leader在发送`AppendEntries`消息时，会附带前一个槽位的信息。

`prevLogIndex`：前一个槽位的位置      `prevLogTerm`：前一个槽位的任期号

（1）Followers在写入Log之前，会检查本地的前一个Log条目是否与Leader发来的有关前一条Log的信息匹配，并返回False/True。

（2）Leader为每个Follower维护了`nextIndex`，`nextIndex`的初始值是从新任Leader的最后一条日志开始。Leader接收到Follower的拒绝后，会减小对应的`nextIndex`，直至与Follower本地的Log匹配。

（3）之后Follower需要先删除本地相应的Log（如果有的话），再用`AppendEntries`中的内容替代本地Log。        而Leader接收到`True`的回应时，会增加相应的`nextIndex`到下一次添加的Log槽位

### 选举约束

在处理别的节点发来的`RequestVote RPC`时，需要做一些检查才能投出赞成票，即节点只能向满足下面条件之一的候选人投出赞成票：

1. 候选人最后一条Log条目的任期号**大于**本地最后一条Log条目的任期号；

2. 或者，候选人最后一条Log条目的任期号**等于**本地最后一条Log条目的任期号，且候选人的Log记录长度**大于等于**本地Log记录的长度

### 快速回复

在日志恢复中，为了避免Leader每次只回退一条Log条目带来耗时长的问题，可以让Follower在回复Leader的`AppendEntries`消息中，携带3个额外的信息，来加速日志的恢复。这里的回复是指，Follower因为Log信息不匹配，拒绝了Leader的`AppendEntries`之后的回复。这里的三个信息是指：

1. `XTerm`：Follower中与Leader冲突的Log对应的任期号。如果Follower在对应位置没有Log，那么这里会返回 -1。
2. `XIndex`：Follower中，对应任期号为`XTerm`的第一条Log条目的槽位号。
3. `XLen`：如果Follower在对应位置没有Log，那么`XTerm`会返回-1，`XLen`表示空白的Log槽位数。

### 持久化

持久化存储：为了处理大部分服务器同时宕机的场景（如停电），我们不得不让服务器能够将它们的状态存储在某处，这样当供电恢复了之后，还能再次获取这个状态。这里的状态是指，为了让服务器在断电或者整个集群断电后，能够继续运行所必不可少的内容。

需要持久化存储的数据：

1. `Log`：所有的Log条目。这是唯一记录了应用程序状态的地方。
2. `currentTerm`：用来保存已经被使用过的任期号。
3. `votedFor`：存储一个服务器为哪个服务器投过票，避免一个服务器在同一个任期内为多个服务器投票，导致同一个任期有多个Leader。

可见，`currentTerm`和`votedFor`都是用来确保每个任期只有最多一个Leader。

在一个真实的Raft服务器上，意味着将数据写入磁盘，所以你需要一些文件来记录这些数据。可以通过一些批量操作持久化存储数据，从而提升性能。例如，只在服务器回复一个`RPC`或者发送一个`RPC`时，服务器才进行持久化存储，这样可以节省一些持久化存储的操作。

> 之所以这很重要是因为，向磁盘写数据是一个代价很高的操作。如果是一个机械硬盘，我们通过写文件的方式来持久化存储，向磁盘写入任何数据都需要花费大概10毫秒时间。

如果你持久化存储在一个机械硬盘上，那么每个操作至少要10毫秒，这意味着你永远也不可能构建一个每秒能处理超过100个请求的Raft服务。这就是所谓的synchronous disk updates的代价。

如果你想构建一个能每秒处理超过100个请求的系统，这里有多个选择。其中一个就是，你可以使用`SSD`硬盘，或者某种闪存。

如果在UNIX上，你调用了`write`，将一些数据写入之后，你需要调用`fsync`。在大部分系统上，`fsync`可以确保在返回时，所有之前写入的数据已经安全的存储在磁盘的介质上了。之后，如果机器重启了，这些信息还能在磁盘上找到。

如果Leader收到了一个客户端请求，在发送`AppendEntries RPC`给Followers之前，必须要先持久化存储在本地。在回复`AppendEntries` 消息之前，Followers也需要持久化存储这些Log条目到本地。因为它们最终都要commit这个请求，而不能忘记这个请求。

### 日志快照

快照的原理：

1. 对于大多数的应用程序来说，应用程序的状态远小于Log的大小。
2. 在某些时间点，Log和应用程序的状态是可以互换的，它们是用来表示应用程序状态的不同事物。

（在key-value数据库的例子中）快照本质上就是key-value表单。

所以，当Raft认为它的Log将会过于庞大，Raft会要求应用程序在Log的特定位置，对其状态做一个快照。我们接下来将会丢弃所有那个点之前的Log记录。我们还需要为快照标注Log的槽位号，同时持久化存储快照之后的Log。

所以，Raft的持久化存储实际上是持久化应用程序快照，和快照之后的Log。



重启：

重启的时候，必须让Raft有方法知道磁盘中最近的快照和Log的组合，并将快照传递给应用程序。因此，应用程序不仅需要有能力能生成一个快照，它还需要能够吸纳一个之前创建的快照，并通过它稳定的重建自己的内存。
